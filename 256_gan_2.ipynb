{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d2286a55",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import numpy\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.autograd.variable import Variable\n",
    "import torchvision.utils as vutils\n",
    "from torchvision import transforms, datasets\n",
    "import random\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f2e6b08c",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_size = 256\n",
    "batch_size = 32\n",
    "channels = 3\n",
    "latent_size = 128\n",
    "beta_1 = 0.5\n",
    "beta_2 = 0.999\n",
    "num_epochs = 500\n",
    "lr = 0.002"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d447aa68",
   "metadata": {},
   "outputs": [],
   "source": [
    "def weights_init_normal(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find('Conv') != -1:\n",
    "        m.weight.data.normal_(0.0, 0.02)\n",
    "    elif classname.find('BatchNorm') != -1:\n",
    "        m.weight.data.normal_(1.0, 0.02)\n",
    "        m.bias.data.fill_(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f92365c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Generator, self).__init__()\n",
    "\n",
    "        def convlayer(n_input, n_output, k_size=4, stride=2, padding=0):\n",
    "            block = [\n",
    "                nn.ConvTranspose2d(n_input, n_output, kernel_size=k_size, stride=stride, padding=padding, bias=False),\n",
    "                nn.BatchNorm2d(n_output),\n",
    "                nn.ReLU(inplace=True),\n",
    "            ]\n",
    "            return block\n",
    "\n",
    "        self.model = nn.Sequential(\n",
    "            *convlayer(latent_size, 1024, 4, 1, 0),\n",
    "            *convlayer(1024, 512, 4, 2, 1),\n",
    "            *convlayer(512, 256, 4, 2, 1),\n",
    "            *convlayer(256, 128, 4, 2, 1),\n",
    "            *convlayer(128, 64, 4, 2, 1),\n",
    "            *convlayer(64, 32, 4, 2, 1),\n",
    "            nn.ConvTranspose2d(32, channels, 4, 2, 1),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "    def forward(self, z):\n",
    "        z = z.view(-1, latent_size, 1, 1)\n",
    "        img = self.model(z)\n",
    "        return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "2e681a79",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Discriminator, self).__init__()\n",
    "\n",
    "        def convlayer(n_input, n_output, k_size=4, stride=2, padding=0, bn=False):\n",
    "            block = [nn.Conv2d(n_input, n_output, kernel_size=k_size, stride=stride, padding=padding, bias=False)]\n",
    "            if bn:\n",
    "                block.append(nn.BatchNorm2d(n_output))\n",
    "            block.append(nn.LeakyReLU(0.2, inplace=True))\n",
    "            return block\n",
    "\n",
    "        self.model = nn.Sequential(\n",
    "            *convlayer(channels * 2, 32, 4, 2, 1),\n",
    "            *convlayer(32, 64, 4, 2, 1),\n",
    "            *convlayer(64, 128, 4, 2, 1, bn=True),\n",
    "            *convlayer(128, 256, 4, 2, 1, bn=True),\n",
    "            *convlayer(256, 512, 4, 2, 1, bn=True),\n",
    "            *convlayer(512, 1024, 4, 2, 1, bn=True),\n",
    "            nn.Conv2d(1024, 1, 4, 1, 0, bias=False),  # FC with Conv.\n",
    "        )\n",
    "\n",
    "    def forward(self, imgs):\n",
    "        critic_value = self.model(imgs)\n",
    "        critic_value  = critic_value.view(imgs.size(0), -1)\n",
    "        return critic_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "0365ecb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.Resize((img_size, img_size)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean = [0.5, 0.5, 0.5], std = [0.5, 0.5, 0.5])\n",
    "])\n",
    "data = datasets.ImageFolder(root='../abstract_1/smaller_abstract', transform=transform)\n",
    "def generate_random_sample():\n",
    "    while True:\n",
    "        random_indexes = numpy.random.choice(data.__len__(), size=batch_size * 2, replace=False)\n",
    "        batch = [data[i][0] for i in random_indexes]\n",
    "        yield torch.stack(batch, 0)\n",
    "def mse_loss(input, target):\n",
    "    return torch.sum((input - target)**2) / input.data.nelement()\n",
    "random_sample = generate_random_sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "e2492dba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_GAN():\n",
    "    cuda = torch.cuda.is_available()\n",
    "    cuda = False\n",
    "    Tensor = torch.cuda.FloatTensor if cuda else torch.FloatTensor\n",
    "    gan_loss = mse_loss\n",
    "\n",
    "    generator = Generator()\n",
    "    discriminator = Discriminator()\n",
    "\n",
    "    optimizer_D = optim.Adam(discriminator.parameters(), lr=lr, betas=(beta_1, beta_2))\n",
    "    optimizer_G = optim.Adam(generator.parameters(), lr=lr, betas=(beta_1, beta_2))\n",
    "\n",
    "    # Loss record.\n",
    "    g_losses = []\n",
    "    d_losses = []\n",
    "    epochs = []\n",
    "    loss_legend = ['Discriminator', 'Generator']\n",
    "\n",
    "    if cuda:\n",
    "        generator = generator.cuda()\n",
    "        discriminator = discriminator.cuda()\n",
    "\n",
    "    generator.apply(weights_init_normal)\n",
    "    discriminator.apply(weights_init_normal)\n",
    "\n",
    "    noise_fixed = Variable(Tensor(25, latent_size).normal_(0, 1), requires_grad=False)\n",
    "\n",
    "    for it in range(int(num_epochs)):\n",
    "        print('Iter. {}'.format(it))\n",
    "\n",
    "        batch = random_sample.__next__()\n",
    "\n",
    "        imgs_real = Variable(batch.type(Tensor))\n",
    "        imgs_real = torch.cat((imgs_real[0:batch_size, ...], imgs_real[batch_size:batch_size * 2, ...]), 1)\n",
    "        real = Variable(Tensor(batch.size(0)//2, 1).fill_(1.0), requires_grad=False)\n",
    "\n",
    "        noise = Variable(Tensor(batch_size * 2, latent_size).normal_(0, 1))\n",
    "        imgs_fake = generator(noise)\n",
    "        imgs_fake = torch.cat((imgs_fake[0:batch_size, ...], imgs_fake[batch_size:batch_size * 2, ...]), 1)\n",
    "\n",
    "        # == Discriminator update == #\n",
    "        optimizer_D.zero_grad()\n",
    "\n",
    "        c_xr = discriminator(imgs_real)\n",
    "        c_xf = discriminator(imgs_fake.detach())\n",
    "\n",
    "        d_loss = gan_loss(c_xr, torch.mean(c_xf) + real) + gan_loss(c_xf, torch.mean(c_xr) - real)\n",
    "\n",
    "        d_loss.backward()\n",
    "        optimizer_D.step()\n",
    "\n",
    "        # == Generator update == #\n",
    "        batch = random_sample.__next__()\n",
    "\n",
    "        imgs_real = Variable(batch.type(Tensor))\n",
    "        imgs_real = torch.cat((imgs_real[0:batch_size, ...], imgs_real[batch_size:batch_size * 2, ...]), 1)\n",
    "\n",
    "        noise = Variable(Tensor(batch_size * 2, latent_size).normal_(0, 1))\n",
    "        imgs_fake = generator(noise)\n",
    "        imgs_fake = torch.cat((imgs_fake[0:batch_size, ...], imgs_fake[batch_size:batch_size * 2, ...]), 1)\n",
    "\n",
    "        c_xr = discriminator(imgs_real)\n",
    "        c_xf = discriminator(imgs_fake)\n",
    "        real = Variable(Tensor(batch.size(0)//2, 1).fill_(1.0), requires_grad=False)\n",
    "\n",
    "        optimizer_G.zero_grad()\n",
    "\n",
    "        g_loss = gan_loss(c_xf, torch.mean(c_xr) + real) + gan_loss(c_xr, torch.mean(c_xf) - real)\n",
    "\n",
    "        g_loss.backward()\n",
    "        optimizer_G.step()\n",
    "        if it % 25 == 0:\n",
    "\n",
    "                # Keep a record of losses for plotting.\n",
    "            epochs.append(it)\n",
    "            g_losses.append(g_loss.item())\n",
    "            d_losses.append(d_loss.item())\n",
    "\n",
    "                # Generate images for a given set of fixed noise\n",
    "                # so we can track how the GAN learns.\n",
    "            imgs_fake_fixed = generator(noise_fixed).detach().data\n",
    "                #imgs_fake_fixed = imgs_fake_fixed.add_(1).div_(2) # To normalize and display on visdom.\n",
    "            vutils.save_image(vutils.make_grid(imgs_fake_fixed[0], padding=2, normalize=True), 'prog3/'+str(it)+'image' + str(random.random()) + '.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45c8058d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter. 0\n",
      "Iter. 1\n",
      "Iter. 2\n",
      "Iter. 3\n",
      "Iter. 4\n",
      "Iter. 5\n",
      "Iter. 6\n",
      "Iter. 7\n",
      "Iter. 8\n",
      "Iter. 9\n",
      "Iter. 10\n",
      "Iter. 11\n",
      "Iter. 12\n",
      "Iter. 13\n",
      "Iter. 14\n",
      "Iter. 15\n"
     ]
    }
   ],
   "source": [
    "train_GAN()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "e845f004",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41d0e29b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
