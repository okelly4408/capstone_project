{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d2286a55",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import numpy\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.autograd.variable import Variable\n",
    "import torchvision.utils as vutils\n",
    "from torchvision import transforms, datasets\n",
    "import random\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f2e6b08c",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_size = 256\n",
    "batch_size = 32\n",
    "channels = 3\n",
    "latent_size = 128\n",
    "beta_1 = 0.5\n",
    "beta_2 = 0.999\n",
    "num_epochs = 500\n",
    "lr = 0.002"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d447aa68",
   "metadata": {},
   "outputs": [],
   "source": [
    "def weights_init_normal(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find('Conv') != -1:\n",
    "        m.weight.data.normal_(0.0, 0.02)\n",
    "    elif classname.find('BatchNorm') != -1:\n",
    "        m.weight.data.normal_(1.0, 0.02)\n",
    "        m.bias.data.fill_(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f92365c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Generator, self).__init__()\n",
    "\n",
    "        def convlayer(n_input, n_output, k_size=4, stride=2, padding=0):\n",
    "            block = [\n",
    "                nn.ConvTranspose2d(n_input, n_output, kernel_size=k_size, stride=stride, padding=padding, bias=False),\n",
    "                nn.BatchNorm2d(n_output),\n",
    "                nn.ReLU(inplace=True),\n",
    "            ]\n",
    "            return block\n",
    "\n",
    "        self.model = nn.Sequential(\n",
    "            *convlayer(latent_size, 1024, 4, 1, 0),\n",
    "            *convlayer(1024, 512, 4, 2, 1),\n",
    "            *convlayer(512, 256, 4, 2, 1),\n",
    "            *convlayer(256, 128, 4, 2, 1),\n",
    "            *convlayer(128, 64, 4, 2, 1),\n",
    "            *convlayer(64, 32, 4, 2, 1),\n",
    "            nn.ConvTranspose2d(32, channels, 4, 2, 1),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "    def forward(self, z):\n",
    "        z = z.view(-1, latent_size, 1, 1)\n",
    "        img = self.model(z)\n",
    "        return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2e681a79",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Discriminator, self).__init__()\n",
    "\n",
    "        def convlayer(n_input, n_output, k_size=4, stride=2, padding=0, bn=False):\n",
    "            block = [nn.Conv2d(n_input, n_output, kernel_size=k_size, stride=stride, padding=padding, bias=False)]\n",
    "            if bn:\n",
    "                block.append(nn.BatchNorm2d(n_output))\n",
    "            block.append(nn.LeakyReLU(0.2, inplace=True))\n",
    "            return block\n",
    "\n",
    "        self.model = nn.Sequential(\n",
    "            *convlayer(channels * 2, 32, 4, 2, 1),\n",
    "            *convlayer(32, 64, 4, 2, 1),\n",
    "            *convlayer(64, 128, 4, 2, 1, bn=True),\n",
    "            *convlayer(128, 256, 4, 2, 1, bn=True),\n",
    "            *convlayer(256, 512, 4, 2, 1, bn=True),\n",
    "            *convlayer(512, 1024, 4, 2, 1, bn=True),\n",
    "            nn.Conv2d(1024, 1, 4, 1, 0, bias=False),  # FC with Conv.\n",
    "        )\n",
    "\n",
    "    def forward(self, imgs):\n",
    "        critic_value = self.model(imgs)\n",
    "        critic_value  = critic_value.view(imgs.size(0), -1)\n",
    "        return critic_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0365ecb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.Resize((img_size, img_size)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean = [0.5, 0.5, 0.5], std = [0.5, 0.5, 0.5])\n",
    "])\n",
    "data = datasets.ImageFolder(root='../abstract_1/smaller_abstract', transform=transform)\n",
    "def generate_random_sample():\n",
    "    while True:\n",
    "        random_indexes = numpy.random.choice(data.__len__(), size=batch_size * 2, replace=False)\n",
    "        batch = [data[i][0] for i in random_indexes]\n",
    "        yield torch.stack(batch, 0)\n",
    "def mse_loss(input, target):\n",
    "    return torch.sum((input - target)**2) / input.data.nelement()\n",
    "random_sample = generate_random_sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e2492dba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_GAN():\n",
    "    cuda = torch.cuda.is_available()\n",
    "    Tensor = torch.cuda.FloatTensor if cuda else torch.FloatTensor\n",
    "    gan_loss = mse_loss\n",
    "\n",
    "    generator = Generator()\n",
    "    discriminator = Discriminator()\n",
    "\n",
    "    optimizer_D = optim.Adam(discriminator.parameters(), lr=lr, betas=(beta_1, beta_2))\n",
    "    optimizer_G = optim.Adam(generator.parameters(), lr=lr, betas=(beta_1, beta_2))\n",
    "\n",
    "    # Loss record.\n",
    "    g_losses = []\n",
    "    d_losses = []\n",
    "    epochs = []\n",
    "    loss_legend = ['Discriminator', 'Generator']\n",
    "\n",
    "    if cuda:\n",
    "        generator = generator.cuda()\n",
    "        discriminator = discriminator.cuda()\n",
    "\n",
    "    generator.apply(weights_init_normal)\n",
    "    discriminator.apply(weights_init_normal)\n",
    "\n",
    "    noise_fixed = Variable(Tensor(25, latent_size).normal_(0, 1), requires_grad=False)\n",
    "\n",
    "    for it in range(int(num_epochs)):\n",
    "        print('Iter. {}'.format(it))\n",
    "\n",
    "        batch = random_sample.__next__()\n",
    "\n",
    "        imgs_real = Variable(batch.type(Tensor))\n",
    "        imgs_real = torch.cat((imgs_real[0:batch_size, ...], imgs_real[batch_size:batch_size * 2, ...]), 1)\n",
    "        real = Variable(Tensor(batch.size(0)//2, 1).fill_(1.0), requires_grad=False)\n",
    "\n",
    "        noise = Variable(Tensor(batch_size * 2, latent_size).normal_(0, 1))\n",
    "        imgs_fake = generator(noise)\n",
    "        imgs_fake = torch.cat((imgs_fake[0:batch_size, ...], imgs_fake[batch_size:batch_size * 2, ...]), 1)\n",
    "\n",
    "        # == Discriminator update == #\n",
    "        optimizer_D.zero_grad()\n",
    "\n",
    "        c_xr = discriminator(imgs_real)\n",
    "        c_xf = discriminator(imgs_fake.detach())\n",
    "\n",
    "        d_loss = gan_loss(c_xr, torch.mean(c_xf) + real) + gan_loss(c_xf, torch.mean(c_xr) - real)\n",
    "\n",
    "        d_loss.backward()\n",
    "        optimizer_D.step()\n",
    "\n",
    "        # == Generator update == #\n",
    "        batch = random_sample.__next__()\n",
    "\n",
    "        imgs_real = Variable(batch.type(Tensor))\n",
    "        imgs_real = torch.cat((imgs_real[0:batch_size, ...], imgs_real[batch_size:batch_size * 2, ...]), 1)\n",
    "\n",
    "        noise = Variable(Tensor(batch_size * 2, latent_size).normal_(0, 1))\n",
    "        imgs_fake = generator(noise)\n",
    "        imgs_fake = torch.cat((imgs_fake[0:batch_size, ...], imgs_fake[batch_size:batch_size * 2, ...]), 1)\n",
    "\n",
    "        c_xr = discriminator(imgs_real)\n",
    "        c_xf = discriminator(imgs_fake)\n",
    "        real = Variable(Tensor(batch.size(0)//2, 1).fill_(1.0), requires_grad=False)\n",
    "\n",
    "        optimizer_G.zero_grad()\n",
    "\n",
    "        g_loss = gan_loss(c_xf, torch.mean(c_xr) + real) + gan_loss(c_xr, torch.mean(c_xf) - real)\n",
    "\n",
    "        g_loss.backward()\n",
    "        optimizer_G.step()\n",
    "        if it % 25 == 0:\n",
    "\n",
    "                # Keep a record of losses for plotting.\n",
    "            epochs.append(it)\n",
    "            g_losses.append(g_loss.item())\n",
    "            d_losses.append(d_loss.item())\n",
    "\n",
    "                # Generate images for a given set of fixed noise\n",
    "                # so we can track how the GAN learns.\n",
    "            imgs_fake_fixed = generator(noise_fixed).detach().data\n",
    "                #imgs_fake_fixed = imgs_fake_fixed.add_(1).div_(2) # To normalize and display on visdom.\n",
    "            vutils.save_image(vutils.make_grid(imgs_fake_fixed[0], padding=2, normalize=True), 'prog3/'+str(it)+'image' + str(random.random()) + '.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "45c8058d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter. 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\okell\\anaconda3\\lib\\site-packages\\PIL\\Image.py:2918: DecompressionBombWarning: Image size (107327830 pixels) exceeds limit of 89478485 pixels, could be decompression bomb DOS attack.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter. 1\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA out of memory. Tried to allocate 96.00 MiB (GPU 0; 8.00 GiB total capacity; 6.19 GiB already allocated; 0 bytes free; 6.30 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_6600/1484334599.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtrain_GAN\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_6600/1490454740.py\u001b[0m in \u001b[0;36mtrain_GAN\u001b[1;34m()\u001b[0m\n\u001b[0;32m     56\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     57\u001b[0m         \u001b[0mnoise\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mVariable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mTensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_size\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlatent_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnormal_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 58\u001b[1;33m         \u001b[0mimgs_fake\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgenerator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnoise\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     59\u001b[0m         \u001b[0mimgs_fake\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimgs_fake\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m...\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimgs_fake\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mbatch_size\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m...\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     60\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1102\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1103\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_6600/632961004.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, z)\u001b[0m\n\u001b[0;32m     23\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mz\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m         \u001b[0mz\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mz\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mview\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlatent_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 25\u001b[1;33m         \u001b[0mimg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mz\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     26\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1102\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1103\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\container.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    139\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    140\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 141\u001b[1;33m             \u001b[0minput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    142\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    143\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1102\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1103\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\activation.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    347\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    348\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 349\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtanh\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    350\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    351\u001b[0m \u001b[1;32mclass\u001b[0m \u001b[0mSiLU\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mModule\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 96.00 MiB (GPU 0; 8.00 GiB total capacity; 6.19 GiB already allocated; 0 bytes free; 6.30 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
     ]
    }
   ],
   "source": [
    "train_GAN()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00258e11",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
